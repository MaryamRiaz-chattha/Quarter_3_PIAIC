{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkYPhoccSaxIcoOP6Gu3IM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MaryamRiaz-chattha/Quarter_3_PIAIC/blob/main/Assignment_6_Video_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiCRwZMAvABc",
        "outputId": "0db4a5bb-dd52-4a77-f1aa-655433977458"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.6/411.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#The code installs libraries for integrating Google GenAI with LangChain to build AI-powered applications.\n",
        "!pip install -q -U langchain\n",
        "!pip install -q -U google-genai\n",
        "!pip install -q -U langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY_2')"
      ],
      "metadata": {
        "id": "EgMTgDkmvqvK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing ChatGoogleGenerativeAI to interact with Google GenAI\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "# Importing Content and Part to handle text content and parts for GenAI\n",
        "from google.genai.types import Content , Part\n",
        "# Importing Markdown and display to show results in Jupyter notebooks\n",
        "from IPython.display import Markdown,display"
      ],
      "metadata": {
        "id": "hJw4b9dqv6FX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ChatGoogleGenerativeAI with the specified model and settings\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-2.0-flash-exp\",  # The specific AI model to use\n",
        "    api_key = userdata.get(\"GOOGLE_API_KEY_2\"),  # API key for authentication\n",
        "    temperature = 0.5  # Controls randomness in AI responses (0.0 to 1.0)\n",
        ")\n"
      ],
      "metadata": {
        "id": "wCrMVM4QwNGg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used that prompt to create video using free Ai tool named as **invideo AI** \"*Create an enchanting short video that celebrates the love of nature. Show a beautiful sunrise over a peaceful forest, with birds chirping in the early morning light. Slowly transition to a close-up of a vibrant meadow full of colorful flowers, bees buzzing as they gather nectar. Capture the grandeur of towering trees, their leaves rustling gently in the wind, and a calm river flowing through the landscape. Include scenes of animals peacefully coexisting, such as deer grazing and butterflies fluttering by. End the video with a breathtaking sunset, where the sky is painted in warm hues of orange, pink, and purple, reflecting the serene connection between humanity and the earth. The video should evoke feelings of serenity, peace, and a profound love for nature*.\""
      ],
      "metadata": {
        "id": "EkCj2D169BZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Upload the file manually via Colab interface\n",
        "# Go to the left sidebar > Files > Upload a file\n",
        "\n",
        "# Step 2: Specify the direct path of the uploaded video\n",
        "video_file_path = \"/content/nature's_love.mp4\"  #uploaded the video from local storage.\n",
        "\n",
        "# Step 3: Use the file path\n",
        "print(f\"The video file is accessible at: {video_file_path}\")\n",
        "\n",
        "# Example of accessing the file for further processing\n",
        "# (You can replace this with your video processing code)\n",
        "with open(video_file_path, \"rb\") as video_file:\n",
        "    print(f\"File {video_file_path} is ready for processing.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dg1G8ph1rvI",
        "outputId": "681ff82a-4944-4e03-d50a-06353cfce8db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The video file is accessible at: /content/nature's_love.mp4\n",
            "File /content/nature's_love.mp4 is ready for processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This function uploads a video to Google GenAI and waits for it to finish processing\n",
        "import time\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=userdata.get(\"GOOGLE_API_KEY_2\"))\n",
        "video_file_path = \"/content/nature's_love.mp4\"\n",
        "\n",
        "\n",
        "def upload_video(video_file_name):\n",
        "  video_file = client.files.upload(path = video_file_name)\n",
        "  while video_file.state == \"PROCESSING\":\n",
        "    print(\"Video Is Being Processed , Kindly Wait!\")\n",
        "    time.sleep(10)\n",
        "    video_file = client.files.get(name = video_file.name or \"\")\n",
        "  if video_file.state == \"SUCCESS\":\n",
        "    pass\n",
        "  elif video_file.state == \"FAILED\":\n",
        "    raise ValueError(video_file.state)\n",
        "  print(f'Video processing complete: ' + (video_file.uri or \"\"))\n",
        "  return video_file"
      ],
      "metadata": {
        "id": "PkSpQ0f52ERo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_nature = upload_video(video_file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0aOujCW3JC7",
        "outputId": "3aa639f2-e234-4010-a3b4-d37a8a0322b1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Is Being Processed , Kindly Wait!\n",
            "Video processing complete: https://generativelanguage.googleapis.com/v1beta/files/jc9i6c4j7qyd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   The function sends the video file and a prompt to the Google GenAI model for processing.\n",
        "*   It then generates descriptive captions and timecodes for every scene in the video.\n",
        "\n",
        "*   Finally, it prints and displays the analysis results in markdown format.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YfKGT6YI_Io6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_video_with_langchain(video_file):\n",
        "  prompt_template = \"\"\"For every scene in this video, provide descriptive captions\n",
        " summarizing the visuals along with any spoken dialogue enclosed in quotation marks.\n",
        " Include each caption in an object, along with its corresponding timecode within the video. \"\"\"\n",
        "\n",
        "  response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    contents=[\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                Part.from_uri(\n",
        "                    file_uri=video_file.uri or \"\",\n",
        "                    mime_type=video_file.mime_type or \"\"),\n",
        "            ]),\n",
        "        Content(\n",
        "            role=\"user\",\n",
        "            parts=[Part(text=prompt_template)]\n",
        "        )\n",
        "    ]\n",
        "  )\n",
        "  print(\"Video Analysis:\")\n",
        "  display(Markdown(response.text))"
      ],
      "metadata": {
        "id": "WkJvEQ-C2XC1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_1 = video_nature\n",
        "analyze_video_with_langchain(video_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "id": "xOl7V9fq2yqb",
        "outputId": "e75d3c09-57f2-4992-df51-bdc61080e182"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video Analysis:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```json\n[\n  {\n    \"timecode\": \"0:00\",\n    \"caption\": \"A low-angle shot shows a grove of silhouetted trees with the sun rising between them.  'I bet you didn't know the magic that lies within a single sunrise.'\"\n  },\n    {\n    \"timecode\":\"0:02\",\n     \"caption\": \"The rising sun is now seen in full with lens flare. 'Come, let's explore.'\"\n    },\n    {\n    \"timecode\": \"0:05\",\n     \"caption\": \"The sun is partially obstructed by more trees as it rises through the forest. 'Witness the dawn as it caresses the forest with golden light.'\"\n  },\n  {\n     \"timecode\": \"0:09\",\n      \"caption\": \"A small bird is seen among foliage. 'Listen to birdsongs, a gentle prelude to the day.'\"\n  },\n  {\n    \"timecode\": \"0:13\",\n    \"caption\": \"A field of wildflowers in a variety of colors are seen. 'In the meadow, vibrant flowers dance with the bees.'\"\n  },\n   {\n    \"timecode\": \"0:17\",\n     \"caption\": \"Looking up through trees to a blue sky.  'Majestic trees sway, leaves murmuring secrets to the wind.'\"\n  },\n  {\n    \"timecode\": \"0:22\",\n     \"caption\": \"A calm river is seen with trees on either side. 'The river flows, a mirror of tranquility.'\"\n  },\n  {\n     \"timecode\":\"0:25\",\n     \"caption\":\"Deer rest and graze in a green field. 'Deer graze, butterflies flutter by, all in harmony.'\"\n  },\n  {\n     \"timecode\": \"0:29\",\n      \"caption\":\"A landscape with dark clouds and an orange sunset. 'As the sun sets, painting the sky in hues of love, feel the serene embrace of nature.'\"\n  }\n]\n```"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name:Maryam Riaz   PIAIC Id:240367**\n",
        "\n",
        "**Reflection on Using LangChain and LLMs for Video Analysis**\n",
        "\n",
        "Using LangChain and LLMs to generate and analyze videos was an exciting learning experience. It let me automatically generate descriptive captions and summarize video content in just a few lines of code.\n",
        "\n",
        "### Challenges:\n",
        "1.  **API Integration**: Getting LangChain and Google GenAI to smoothly integrate took some effort. First, I needed to ensure that the video was processed correctly before moving forward.\n",
        "2. **Video Processing Time**: Processed large videos took a time, so the patience was involved and different kinds of processing stages had to be handled.\n",
        "3. **Writing Prompts**: Writing good prompts to get right video analysis has been challenging. In some cases, I had to adjust them in order to bring meaningful results back.\n",
        "\n",
        "### My learning\n",
        "1. **How Powerful AI Model is for Videos**: I discovered how powerful an AI model really is when handling tasks like automatic video summarizing and captioning.\n",
        "2. **Testing is Important**: I learned that testing the integration and fine-tuning prompts are crucial to get the best results.\n",
        "3. **Hands-on AI Experience**: This project gave me practical experience in using AI for content generation, which opened up many possibilities for future projects.\n",
        "\n",
        "It was a great introduction to working with LangChain and LLMs, and I feel more confident in using AI tools for real-world applications."
      ],
      "metadata": {
        "id": "aandjwFZBCWE"
      }
    }
  ]
}